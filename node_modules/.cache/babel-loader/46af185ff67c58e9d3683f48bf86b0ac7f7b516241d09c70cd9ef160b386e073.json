{"ast":null,"code":"/**\n * @file Helper module for using model configs. For more information, see the corresponding\n * [Python documentation](https://huggingface.co/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig).\n * \n * **Example:** Load an `AutoConfig`.\n * \n * ```javascript\n * import { AutoConfig } from '@xenova/transformers';\n * let config = await AutoConfig.from_pretrained('bert-base-uncased');\n * console.log(config);\n * // PretrainedConfig {\n * //   \"model_type\": \"bert\",\n * //   \"is_encoder_decoder\": false,\n * //   \"architectures\": [\n * //       \"BertForMaskedLM\"\n * //   ],\n * //   \"vocab_size\": 30522\n * //   \"num_attention_heads\": 12,\n * //   \"num_hidden_layers\": 12,\n * //   \"hidden_size\": 768,\n * //   \"max_position_embeddings\": 512,\n * //   ...\n * // }\n * ```\n * \n * @module configs\n */\n\nimport { getModelJSON } from './utils/hub.js';\n\n/**\n * @typedef {import('./utils/hub.js').PretrainedOptions} PretrainedOptions\n */\n\n/**\n * Loads a config from the specified path.\n * @param {string} pretrained_model_name_or_path The path to the config directory.\n * @param {PretrainedOptions} options Additional options for loading the config.\n * @returns {Promise<Array>} A promise that resolves with information about the loaded config.\n */\nasync function loadConfig(pretrained_model_name_or_path, options) {\n  let info = await getModelJSON(pretrained_model_name_or_path, 'config.json', true, options);\n  return info;\n}\n\n/**\n * Base class for all configuration classes. For more information, see the corresponding\n * [Python documentation](https://huggingface.co/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig).\n */\nexport class PretrainedConfig {\n  // NOTE: Typo in original\n\n  /**\n   * Create a new PreTrainedTokenizer instance.\n   * @param {Object} configJSON The JSON of the config.\n   */\n  constructor(configJSON) {\n    this.model_type = null;\n    this.is_encoder_decoder = false;\n    Object.assign(this, configJSON);\n  }\n\n  /**\n   * Loads a pre-trained config from the given `pretrained_model_name_or_path`. \n   * \n   * @param {string} pretrained_model_name_or_path The path to the pre-trained config.\n   * @param {PretrainedOptions} options Additional options for loading the config.\n   * @throws {Error} Throws an error if the config.json is not found in the `pretrained_model_name_or_path`.\n   * \n   * @returns {Promise<PretrainedConfig>} A new instance of the `PretrainedConfig` class.\n   */\n  static async from_pretrained(pretrained_model_name_or_path, {\n    progress_callback = null,\n    config = null,\n    cache_dir = null,\n    local_files_only = false,\n    revision = 'main'\n  } = {}) {\n    let data = config ?? (await loadConfig(pretrained_model_name_or_path, {\n      progress_callback,\n      config,\n      cache_dir,\n      local_files_only,\n      revision\n    }));\n    return new this(data);\n  }\n}\n\n/**\n * Helper class which is used to instantiate pretrained configs with the `from_pretrained` function.\n * \n * @example\n * let config = await AutoConfig.from_pretrained('bert-base-uncased'); \n */\nexport class AutoConfig {\n  /** @type {PretrainedConfig.from_pretrained} */\n  static async from_pretrained(...args) {\n    return PretrainedConfig.from_pretrained(...args);\n  }\n}","map":{"version":3,"names":["getModelJSON","loadConfig","pretrained_model_name_or_path","options","info","PretrainedConfig","constructor","configJSON","model_type","is_encoder_decoder","Object","assign","from_pretrained","progress_callback","config","cache_dir","local_files_only","revision","data","AutoConfig","args"],"sources":["/workspaces/calico/node_modules/@xenova/transformers/src/configs.js"],"sourcesContent":["\n/**\n * @file Helper module for using model configs. For more information, see the corresponding\n * [Python documentation](https://huggingface.co/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig).\n * \n * **Example:** Load an `AutoConfig`.\n * \n * ```javascript\n * import { AutoConfig } from '@xenova/transformers';\n * let config = await AutoConfig.from_pretrained('bert-base-uncased');\n * console.log(config);\n * // PretrainedConfig {\n * //   \"model_type\": \"bert\",\n * //   \"is_encoder_decoder\": false,\n * //   \"architectures\": [\n * //       \"BertForMaskedLM\"\n * //   ],\n * //   \"vocab_size\": 30522\n * //   \"num_attention_heads\": 12,\n * //   \"num_hidden_layers\": 12,\n * //   \"hidden_size\": 768,\n * //   \"max_position_embeddings\": 512,\n * //   ...\n * // }\n * ```\n * \n * @module configs\n */\n\nimport {\n    getModelJSON,\n} from './utils/hub.js';\n\n/**\n * @typedef {import('./utils/hub.js').PretrainedOptions} PretrainedOptions\n */\n\n\n/**\n * Loads a config from the specified path.\n * @param {string} pretrained_model_name_or_path The path to the config directory.\n * @param {PretrainedOptions} options Additional options for loading the config.\n * @returns {Promise<Array>} A promise that resolves with information about the loaded config.\n */\nasync function loadConfig(pretrained_model_name_or_path, options) {\n    let info = await getModelJSON(pretrained_model_name_or_path, 'config.json', true, options);\n    return info;\n}\n\n/**\n * Base class for all configuration classes. For more information, see the corresponding\n * [Python documentation](https://huggingface.co/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig).\n */\nexport class PretrainedConfig {\n    // NOTE: Typo in original\n\n    /**\n     * Create a new PreTrainedTokenizer instance.\n     * @param {Object} configJSON The JSON of the config.\n     */\n    constructor(configJSON) {\n        this.model_type = null;\n        this.is_encoder_decoder = false;\n\n        Object.assign(this, configJSON);\n    }\n\n    /**\n     * Loads a pre-trained config from the given `pretrained_model_name_or_path`. \n     * \n     * @param {string} pretrained_model_name_or_path The path to the pre-trained config.\n     * @param {PretrainedOptions} options Additional options for loading the config.\n     * @throws {Error} Throws an error if the config.json is not found in the `pretrained_model_name_or_path`.\n     * \n     * @returns {Promise<PretrainedConfig>} A new instance of the `PretrainedConfig` class.\n     */\n    static async from_pretrained(pretrained_model_name_or_path, {\n        progress_callback = null,\n        config = null,\n        cache_dir = null,\n        local_files_only = false,\n        revision = 'main',\n    } = {}) {\n\n        let data = config ?? await loadConfig(pretrained_model_name_or_path, {\n            progress_callback,\n            config,\n            cache_dir,\n            local_files_only,\n            revision,\n        })\n        return new this(data);\n    }\n}\n\n/**\n * Helper class which is used to instantiate pretrained configs with the `from_pretrained` function.\n * \n * @example\n * let config = await AutoConfig.from_pretrained('bert-base-uncased'); \n */\nexport class AutoConfig {\n    /** @type {PretrainedConfig.from_pretrained} */\n    static async from_pretrained(...args) {\n        return PretrainedConfig.from_pretrained(...args);\n    }\n}\n"],"mappings":"AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,SACIA,YAAY,QACT,gBAAgB;;AAEvB;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA,eAAeC,UAAUA,CAACC,6BAA6B,EAAEC,OAAO,EAAE;EAC9D,IAAIC,IAAI,GAAG,MAAMJ,YAAY,CAACE,6BAA6B,EAAE,aAAa,EAAE,IAAI,EAAEC,OAAO,CAAC;EAC1F,OAAOC,IAAI;AACf;;AAEA;AACA;AACA;AACA;AACA,OAAO,MAAMC,gBAAgB,CAAC;EAC1B;;EAEA;AACJ;AACA;AACA;EACIC,WAAWA,CAACC,UAAU,EAAE;IACpB,IAAI,CAACC,UAAU,GAAG,IAAI;IACtB,IAAI,CAACC,kBAAkB,GAAG,KAAK;IAE/BC,MAAM,CAACC,MAAM,CAAC,IAAI,EAAEJ,UAAU,CAAC;EACnC;;EAEA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACI,aAAaK,eAAeA,CAACV,6BAA6B,EAAE;IACxDW,iBAAiB,GAAG,IAAI;IACxBC,MAAM,GAAG,IAAI;IACbC,SAAS,GAAG,IAAI;IAChBC,gBAAgB,GAAG,KAAK;IACxBC,QAAQ,GAAG;EACf,CAAC,GAAG,CAAC,CAAC,EAAE;IAEJ,IAAIC,IAAI,GAAGJ,MAAM,KAAI,MAAMb,UAAU,CAACC,6BAA6B,EAAE;MACjEW,iBAAiB;MACjBC,MAAM;MACNC,SAAS;MACTC,gBAAgB;MAChBC;IACJ,CAAC,CAAC;IACF,OAAO,IAAI,IAAI,CAACC,IAAI,CAAC;EACzB;AACJ;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMC,UAAU,CAAC;EACpB;EACA,aAAaP,eAAeA,CAAC,GAAGQ,IAAI,EAAE;IAClC,OAAOf,gBAAgB,CAACO,eAAe,CAAC,GAAGQ,IAAI,CAAC;EACpD;AACJ","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}