{"ast":null,"code":"// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\nexport { registerBackend } from './backend-impl';","map":{"version":3,"names":["registerBackend"],"sources":["/Users/lorryrio/Project/calico/node_modules/onnxruntime-common/lib/backend.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession} from './inference-session';\nimport {OnnxValue} from './onnx-value';\n\n/**\n * @internal\n */\nexport declare namespace SessionHandler {\n  type FeedsType = {[name: string]: OnnxValue};\n  type FetchesType = {[name: string]: OnnxValue | null};\n  type ReturnType = {[name: string]: OnnxValue};\n}\n\n/**\n * Represent a handler instance of an inference session.\n *\n * @internal\n */\nexport interface SessionHandler {\n  dispose(): Promise<void>;\n\n  readonly inputNames: readonly string[];\n  readonly outputNames: readonly string[];\n\n  startProfiling(): void;\n  endProfiling(): void;\n\n  run(feeds: SessionHandler.FeedsType, fetches: SessionHandler.FetchesType,\n      options: InferenceSession.RunOptions): Promise<SessionHandler.ReturnType>;\n}\n\n/**\n * Represent a backend that provides implementation of model inferencing.\n *\n * @internal\n */\nexport interface Backend {\n  /**\n   * Initialize the backend asynchronously. Should throw when failed.\n   */\n  init(): Promise<void>;\n\n  createSessionHandler(uriOrBuffer: string|Uint8Array, options?: InferenceSession.SessionOptions):\n      Promise<SessionHandler>;\n}\n\nexport {registerBackend} from './backend-impl';\n"],"mappings":"AAAA;AACA;AA+CA,SAAQA,eAAe,QAAO,gBAAgB","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}